{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youdanzh/CIS700-projects/blob/main/transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pasXsTAnxxsB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch as tr\n",
        "import matplotlib.pyplot as pt\n",
        "from tqdm.notebook import trange\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "examples = []\n",
        "error =\".ipynb_checkpoints\"\n",
        "for file in os.listdir(\"data/\"):\n",
        " filename = os.fsdecode(file)\n",
        " print(filename)\n",
        " header = True\n",
        " path = \"data/\" + filename\n",
        " if(filename!=error):\n",
        "   with open(path, \"r\") as f:\n",
        "    counter = 0\n",
        "    clause = \"\"\n",
        "    for line in f:\n",
        "      counter += 1\n",
        "      if line[0] == \"T\" and counter == 3:\n",
        "        clause = line[2:]\n",
        "      if line[0] in \"+-\":\n",
        "        header = False\n",
        "        label = 0 if line[0] == \"-\" else 1\n",
        "      elif not header:\n",
        "        clause_steps = line[2:]+ \" & \" + clause\n",
        "        #print(clause_steps)\n",
        "        examples.append((clause_steps,label))\n",
        "      \n",
        "for (example,label) in enumerate(examples[:10]):\n",
        "   print(example,label)"
      ],
      "metadata": {
        "id": "jc3_LC6HG3Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "examples = []\n",
        "header = True\n",
        "\n",
        "with open(\"data/00001\", \"r\") as f:\n",
        "  counter = 0\n",
        "  clause = \"\"\n",
        "  for line in f:\n",
        "    counter += 1\n",
        "    if line[0] == \"T\" and counter == 3:\n",
        "      clause = line[2:]\n",
        "    if line[0] in \"+-\":\n",
        "      header = False\n",
        "      label = 0 if line[0] == \"-\" else 1\n",
        "    elif not header:\n",
        "      clause_steps = line[2:] + \" & \" + clause\n",
        "      #print(clause_steps)\n",
        "      examples.append((clause_steps.strip(),label))\n",
        "      \n",
        "#for e,(example,label) in enumerate(examples[:10]):\n",
        " # print(label, example)\n",
        "for i in range(10):\n",
        "  print(examples[i])\n",
        "len(examples)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dkdllvdayS73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation = []\n",
        "header = True\n",
        "\n",
        "with open(\"00011\", \"r\") as f:\n",
        "  counter = 0\n",
        "  clause = \"\"\n",
        "  for line in f:\n",
        "    counter += 1\n",
        "    if line[0] == \"T\" and counter == 3:\n",
        "      clause = line[2:]\n",
        "    if line[0] in \"+-\":\n",
        "      header = False\n",
        "      label = 0 if line[0] == \"-\" else 1\n",
        "    elif not header:\n",
        "      clause_steps = line[2:] + \" & \" + clause\n",
        "      #print(clause_steps)\n",
        "      validation.append((clause_steps.strip(),label))\n",
        "      \n",
        "      \n"
      ],
      "metadata": {
        "id": "qqgNfQ8lsgn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chrs = \"\".join([chr(c) for c in range(ord(\"a\"), ord(\"z\"))] + [chr(c) for c in range(ord(\"A\"), ord(\"Z\"))] + [\"_\"])\n",
        "print(chrs)\n",
        "\n",
        "def parse(line):\n",
        "  tokens = []\n",
        "  token = \"\"\n",
        "  for c in line:\n",
        "    if c in chrs: token += c\n",
        "    else:\n",
        "      tokens.append(token.lstrip())\n",
        "      token = c\n",
        "  tokens.append(token.lstrip())\n",
        "  return tokens\n",
        "\n",
        "print(parse(examples[0][0]))"
      ],
      "metadata": {
        "id": "JY79W1PQyc1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = set()\n",
        "for example, label in examples:\n",
        "  tokens = parse(example) \n",
        "  all_tokens |= set(tokens)\n",
        "\n",
        "for example_2, label_2 in validation:\n",
        "  tokens = parse(example_2) \n",
        "  all_tokens |= set(tokens)\n",
        "\n",
        "\n",
        "all_tokens = list(all_tokens)\n",
        "lookup = {token: t for (t, token) in enumerate(all_tokens)}\n",
        "\n",
        "print(lookup)\n",
        "for token in all_tokens: print(token)\n",
        "print(len(all_tokens))\n"
      ],
      "metadata": {
        "id": "TUqbbmcwzqyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(parse(example)) for example,label in examples])\n",
        "print(\"max_len:\", max_len)\n",
        "embeddings = tr.eye(len(all_tokens))"
      ],
      "metadata": {
        "id": "0AbJUTUzzvp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Transformer utilities\n",
        "\"\"\"\n",
        "def embed(seq, max_len, embeddings, offset=0):\n",
        "    embedded = tr.zeros(max_len, embeddings.shape[1])\n",
        "    cap = min(len(seq), max_len-offset)\n",
        "    if cap > 0:\n",
        "        embedded[offset:offset+cap] = tr.stack(tuple(embeddings[lookup[token]] for token in seq[:cap]))\n",
        "    return embedded\n",
        "\n",
        "def Attention(Q, K, V, masked=False):\n",
        "    dk = Q.shape[1]\n",
        "    logits = Q @ K.t() / dk**.5\n",
        "    if masked:\n",
        "        idx = tr.arange(Q.shape[0])\n",
        "        logits[idx.unsqueeze(1) < idx] = -tr.inf\n",
        "    return tr.softmax(logits, dim=1) @ V\n",
        "\n",
        "class MultiHeadAttention(tr.nn.Module):\n",
        "    def __init__(self, num_heads, d_model, masked=False, projections=\"\"):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        dh = d_model // num_heads\n",
        "        self.masked = masked\n",
        "        self.num_heads = num_heads\n",
        "        self.WQ, self.WK, self.WV = tuple(\n",
        "            tr.nn.ModuleList([tr.nn.Linear(d_model, dh, bias=False) for i in range(num_heads)])\n",
        "            if p in projections else [lambda x: x[:,:dh]]*num_heads\n",
        "            for p in \"QKV\")\n",
        "        self.WO = tr.nn.Linear(dh * num_heads, d_model, bias=False) if \"O\" in projections else lambda x: x\n",
        "        self.ln = tr.nn.LayerNorm(d_model)\n",
        "        self.projections = projections\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        heads = [\n",
        "            Attention(self.WQ[i](Q), self.WK[i](K), self.WV[i](V), self.masked)\n",
        "            for i in range(self.num_heads)]\n",
        "        out = self.WO(tr.cat(heads, dim=1))\n",
        "        out += Q # skip connection\n",
        "        out = self.ln(out) # layer normalization\n",
        "        return out\n",
        "\n",
        "# requires d_model - d_embedding >= max_len\n",
        "def one_hot_positional_encoder(max_len):\n",
        "    def encode_position(inputs):\n",
        "        I = tr.eye(max_len)\n",
        "        return tr.cat((I, inputs), dim=1)\n",
        "    return encode_position\n",
        "\n"
      ],
      "metadata": {
        "id": "-8Chz1jOzx_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(tr.nn.Module):\n",
        "  def __init__(self, num_blocks, num_heads):\n",
        "    super(Net, self).__init__()\n",
        "    d_model = max_len+embeddings.shape[1]\n",
        "    self.encoder = one_hot_positional_encoder(max_len)\n",
        "    self.blocks = tr.nn.ModuleList([\n",
        "      MultiHeadAttention(num_heads, d_model, projections=\"QKVO\")\n",
        "      for _ in range(num_blocks)\n",
        "    ])\n",
        "    self.readout = tr.nn.Linear(d_model, 2)\n",
        "  def forward(self, example):\n",
        "    x = embed(parse(example), max_len, embeddings)\n",
        "    x = self.encoder(x)\n",
        "    for mha in self.blocks:\n",
        "      x = mha(x, x, x)\n",
        "    y = self.readout(x).mean(dim=0).unsqueeze(0)\n",
        "    return y\n",
        "\n",
        "net = Net(3, 4)\n",
        "y = net(examples[0][0])\n",
        "print(y)"
      ],
      "metadata": {
        "id": "MUinbtDAz0e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(2, 4)\n",
        "xc = tr.nn.CrossEntropyLoss()\n",
        "if tr.cuda.is_available():\n",
        "    net= net.cuda()\n",
        "\n",
        "opt = tr.optim.Adam(net.parameters(), lr=0.0001)\n",
        "\n",
        "num_iters = 200\n",
        "verb_step = 20\n",
        "train_loss = []\n",
        "valid_accu =[]\n",
        "valid_loss =[]\n",
        "for i in trange(num_iters):\n",
        "\n",
        "    example, label = random.choice(examples)\n",
        "    if tr.cuda.is_available():\n",
        "          example , label = example.cuda(non_blocking=True), label.cuda(non_blocking=True)\n",
        "    logits = net(example)\n",
        "    loss = xc(logits, tr.tensor([label]))\n",
        "    train_loss.append(loss.item())\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    correct = []\n",
        "    vloss = []\n",
        "    \n",
        "    \n",
        "    if i % verb_step == 0 or i == num_iters-1:\n",
        "       \n",
        "        with tr.no_grad():\n",
        "            for example_2, label_2 in validation:\n",
        "               if tr.cuda.is_available():\n",
        "                    example_2, label_2 = example_2.cuda(), label_2.cuda()\n",
        "               logits = net(example_2)\n",
        "               v_loss = xc(logits,tr.tensor([label_2]))  \n",
        "               pred = logits.argmax()\n",
        "               correct.append(np.absolute(label_2-pred))\n",
        "               vloss.append(v_loss.item())\n",
        "        valid_accu.append(1-np.mean(correct))\n",
        "        valid_loss.append(np.mean(vloss))\n",
        "        print(f'loss:{loss.item()} \\t\\tval_loss: {np.mean(vloss)}\\t\\t val_acc: {1-np.mean(correct)}  ')\n",
        "        \n",
        "              \n",
        "\n",
        "#pt.plot(prediction)\n",
        "pt.plot(train_loss)\n",
        "pt.xlabel(\"Iteration\")\n",
        "pt.ylabel(\"Loss\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jshKLvyKz3U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T_GE5_MhKnl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt.plot(valid_accu)\n",
        "pt.xlabel(\"Num measurement\")\n",
        "pt.ylabel(\"accuracy\")"
      ],
      "metadata": {
        "id": "9y5RmPy5EkwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(tr.nn.Module):\n",
        "  def __init__(self, num_blocks, num_heads):\n",
        "    super(Net, self).__init__()\n",
        "    d_model = max_len+embeddings.shape[1]\n",
        "    self.conv = tr.nn.Conv1d(max_len,max_len, kernel_size=1)    \n",
        "    self.encoder = one_hot_positional_encoder(max_len)\n",
        "    self.blocks = tr.nn.ModuleList([\n",
        "      MultiHeadAttention(num_heads, d_model, projections=\"QKVO\")\n",
        "      for _ in range(num_blocks)\n",
        "    ])\n",
        "    self.readout =tr.nn.Linear(d_model, 2)\n",
        "    \n",
        "  def forward(self, example):\n",
        "    x = embed(parse(example), max_len, embeddings)\n",
        "    x = self.encoder(x)\n",
        "    x = self.conv(x)\n",
        "    for mha in self.blocks:\n",
        "      x = mha(x, x, x)\n",
        "    x=self.conv(x)\n",
        "    y = self.readout(x).mean(dim=0).unsqueeze(0)\n",
        "    return y"
      ],
      "metadata": {
        "id": "IdN3hwg0RPc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Peter's Implementation"
      ],
      "metadata": {
        "id": "Y_QjZo8wKr66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(4, 8)\n",
        "xc = tr.nn.CrossEntropyLoss()\n",
        "if tr.cuda.is_available():\n",
        "    net= net.cuda()\n",
        "\n",
        "opt = tr.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "num_iters = 200\n",
        "verb_step = 20\n",
        "train_loss = []\n",
        "valid_accu =[]\n",
        "valid_loss =[]\n",
        "for i in trange(num_iters):\n",
        "\n",
        "    example, label = random.choice(examples)\n",
        "    if tr.cuda.is_available():\n",
        "          example , label = example.cuda(), label.cuda()\n",
        "    logits = net(example)\n",
        "    loss = xc(logits, tr.tensor([label]))\n",
        "    train_loss.append(loss.item())\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    correct = []\n",
        "    vloss = []\n",
        "    \n",
        "    \n",
        "    if i % verb_step == 0 or i == num_iters-1:\n",
        "       \n",
        "        with tr.no_grad():\n",
        "            for example_2, label_2 in validation:\n",
        "               if tr.cuda.is_available():\n",
        "                    example_2, label_2 = example_2.cuda(), label_2.cuda()\n",
        "               logits = net(example_2)\n",
        "               v_loss = xc(logits,tr.tensor([label_2]))  \n",
        "               pred = logits.argmax()\n",
        "               correct.append(np.absolute(label_2-pred))\n",
        "               vloss.append(v_loss.item())\n",
        "        valid_accu.append(1-np.mean(correct))\n",
        "        valid_loss.append(np.mean(vloss))\n",
        "        print(f'loss:{loss.item()} \\t\\tval_loss: {np.mean(vloss)}\\t\\t val_acc: {1-np.mean(correct)}  ')\n",
        "        \n",
        "              \n",
        "\n",
        "#pt.plot(prediction)\n",
        "pt.plot(train_loss)\n",
        "pt.xlabel(\"Iteration\")\n",
        "pt.ylabel(\"Loss\")\n"
      ],
      "metadata": {
        "id": "FuTlkI4nS7xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt.plot(valid_accu)\n",
        "pt.xlabel(\"Num measurement\")\n",
        "pt.ylabel(\"accuracy\")"
      ],
      "metadata": {
        "id": "WQmz87HPE0u4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}